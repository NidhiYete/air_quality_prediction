{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-13T18:52:34.413940800Z",
     "start_time": "2024-02-13T18:52:33.986115600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import aqi\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Extraction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a4548c3fa6f729"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "url_template = \"https://api.openaq.org/v2/measurements?country=IN&location_id={}&date_from={}&date_to={}&limit={}&page={}&offset=0&sort=asc&radius=1000&order_by=datetime\"\n",
    "headers = {\"accept\": \"application/json\"}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ce54b25b37078a0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "limit = 1000  # Set desired limit\n",
    "locationId = 407\n",
    "# Set the initial date range\n",
    "current_date_from = datetime(2023, 1, 1)\n",
    "current_date_to = datetime(2023, 1, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "936e47012cca97c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set the end date for the loop\n",
    "end_date = datetime(2023, 12, 31)\n",
    "response_list = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c42539b2a74943f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "page = 1\n",
    "while current_date_from < end_date:\n",
    "    date_from_str = current_date_from.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    next_month = current_date_from + relativedelta(months=1)\n",
    "    date_to_str = next_month.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "    url = url_template.format(locationId, date_from_str, date_to_str, limit, page)\n",
    "    print(\"url : \"+url)\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the \"found\" value from the JSON content\n",
    "        json_response = response.json()\n",
    "        found_value_str = str(json_response[\"meta\"][\"found\"])\n",
    "        limit_value_str = json_response[\"meta\"][\"limit\"]\n",
    "        result_count = json_response['results']\n",
    "        response_list.extend(json_response['results'])\n",
    "        #print(json_response)\n",
    "        limit_value = int(limit_value_str)\n",
    "        # Remove \">\" and convert to numeric type\n",
    "        if result_count:\n",
    "            if '>' in found_value_str:\n",
    "                found_value = int(found_value_str.replace('>', ''))\n",
    "            else:\n",
    "                found_value = int (found_value_str)\n",
    "        else:\n",
    "            found_value = 0\n",
    "        # Print \"more\" or \"done\" based on the limit\n",
    "        if found_value > 0:\n",
    "            print(\"more\")\n",
    "            #print(response.text)\n",
    "            page += 1  # Increment the page number for the next iteration\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(\"updating date - as page limit for date range is met.\")\n",
    "            # Update date range for the next iteration\n",
    "            current_date_from = next_month\n",
    "            page = 1\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        break  # Exit the loop on error"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc512c24d47d48f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#creating an empty dataframe\n",
    "# Create an empty dictionary to store DataFrames for each locationId\n",
    "dfs = {}\n",
    "\n",
    "# Loop through response_data and extract relevant information\n",
    "for entry in response_list:\n",
    "    location_id = entry[\"locationId\"]\n",
    "    date_utc = entry[\"date\"][\"utc\"]\n",
    "    location = entry[\"location\"]\n",
    "    coordinates = entry[\"coordinates\"]\n",
    "    country = entry[\"country\"]\n",
    "    city = entry[\"city\"]\n",
    "    parameter = entry[\"parameter\"]\n",
    "    value = entry[\"value\"]\n",
    "\n",
    "    # Check if the locationId exists in the dictionary\n",
    "    if location_id not in dfs:\n",
    "        # If the locationId is not in the dictionary, create a new DataFrame for it\n",
    "        dfs[location_id] = pd.DataFrame({\n",
    "            'locationId': [location_id],\n",
    "            'date_utc': [date_utc],\n",
    "            'location': [location],\n",
    "            'coordinates': [coordinates],\n",
    "            'country': [country],\n",
    "            'city': [city],\n",
    "            parameter: [value]\n",
    "        })\n",
    "    else:\n",
    "        # If location_id and date_utc combination already exists in the DataFrame, update the corresponding parameter value\n",
    "        if any((dfs[location_id]['date_utc'].eq(date_utc))):\n",
    "            dfs[location_id].loc[dfs[location_id]['date_utc'].eq(date_utc), parameter] = value\n",
    "        else:\n",
    "            # Create a new row for the combination of location_id and date_utc\n",
    "            dfs[location_id] = pd.concat([dfs[location_id], pd.DataFrame({\n",
    "                'locationId': [location_id],\n",
    "                'date_utc': [date_utc],\n",
    "                'location': [location],\n",
    "                'coordinates': [coordinates],\n",
    "                'country': [country],\n",
    "                'city': [city],\n",
    "                parameter: [value]\n",
    "            })])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddd717d8eb16bf33"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Combine all DataFrames into a single DataFrame (if needed)\n",
    "df_combined = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "# Reset the index of the combined DataFrame\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e18192c2dae91c1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#target folder within project\n",
    "target_folder='target'\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "excel_file_path = os.path.join(target_folder, f'output_{timestamp}.xlsx')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47e12f6af8ddb166"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_combined.to_excel(excel_file_path, index=False)\n",
    "print('Excel File generated Successfully')\n",
    "print('program exit')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ac20656912097d0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get a list of all Excel files in the folder\n",
    "excel_files = [file for file in os.listdir(target_folder) if file.endswith('.xlsx')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0580920f322c0d1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create an empty list to store DataFrames\n",
    "aqs = []\n",
    "\n",
    "# Loop through each Excel file and read it into a DataFrame\n",
    "for excel_file in excel_files:\n",
    "    file_path = os.path.join(target_folder, excel_file)\n",
    "    aq = pd.read_excel(file_path)\n",
    "    aqs.append(aq)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a5bf20f3d456aa1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_aq = pd.concat(aqs, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eff559c8414e1d25"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read Excel file\n",
    "combined_aq.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8288962e42600417"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a new Excel file\n",
    "combined_excel_path = os.path.join(target_folder, 'air_quality.xlsx')\n",
    "combined_aq.to_excel(combined_excel_path, index=False)\n",
    "\n",
    "print('Combined Excel File generated successfully.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b31f6ee8284587b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New data_2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85d70943cc8328e4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Excel File generated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder where your CSV files are located\n",
    "folder_path = Path('data_2')\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate over all CSV files in the specified folder\n",
    "for file_path in folder_path.glob(\"*.csv\"):\n",
    "    # Read CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the DataFrames along the rows\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Convert the 'date' column to datetime format if it's not already\n",
    "combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "\n",
    "# Sort the DataFrame by the 'date' column in ascending order\n",
    "combined_df = combined_df.sort_values(by='date')\n",
    "\n",
    "# Reset the index\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('air_data.csv', index=False)\n",
    "print('Combined Excel File generated successfully.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-14T04:07:33.759763700Z",
     "start_time": "2024-02-14T04:07:33.544176600Z"
    }
   },
   "id": "10bc4f0b68e87668",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "84bfa90daddf5f10"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
